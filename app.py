import streamlit as st
import json
from langchain_openai import ChatOpenAI
from langchain_teddynote.document_loaders import HWPLoader
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
import os
import pathlib
import toml

# Streamlitì˜ ê¸°ë³¸ ë©”ë‰´ì™€ í‘¸í„° ìˆ¨ê¸°ê¸°
hide_github_icon = """
    <style>
    .css-1jc7ptx, .e1ewe7hr3, .viewerBadge_container__1QSob,
    .styles_viewerBadge__1yB5_, .viewerBadge_link__1S137,
    .viewerBadge_text__1JaDK{ display: none; }
    #MainMenu{ visibility: hidden; }
    footer { visibility: hidden; }
    header { visibility: hidden; }
    </style>
"""

# secrets.toml íŒŒì¼ ê²½ë¡œ
secrets_path = pathlib.Path(__file__).parent.parent / ".streamlit/secrets.toml"

# secrets.toml íŒŒì¼ ì½ê¸°
with open(secrets_path, "r") as f:
    secrets = toml.load(f)

# OpenAI API í‚¤ ë¡œë“œ
openai_api_key = secrets.get("OPENAI_API_KEY")

# JSON íŒŒì¼ ê²½ë¡œ
json_file_path = pathlib.Path(__file__).parent / "training_data.json"

# JSON ë°ì´í„° ë¡œë“œ
def load_json_data(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

json_data = load_json_data(json_file_path)

# Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª©
st.title("ë””ì§€í„¸ë°°ì§€ ì„¤ëª… ë° ë°œê¸‰ì¡°ê±´ ìƒì„±ê¸°")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "uploaded_file" not in st.session_state:
    st.session_state["uploaded_file"] = None

# ì‚¬ì´ë“œë°”ì— íŒŒì¼ ì—…ë¡œë“œ
with st.sidebar:
    st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("ì—°ìˆ˜ê³„íšì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf", "hwp", "hwpx"])
    if uploaded_file:
        st.session_state["uploaded_file"] = uploaded_file

# ë³¸ë¬¸ì— ë“œë¡­ë‹¤ìš´ ë©”ë‰´ì™€ ë²„íŠ¼ ì¶”ê°€
st.subheader("ğŸ“ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")

col1, col2 = st.columns(2)

with col1:
    content_option = st.selectbox("ì—°ìˆ˜ ë‚´ìš© ê¸°ì¤€ ì„ íƒ", [content['category'] for content in json_data['content_standards']])
    
with col2:
    level_option = st.selectbox("ì—°ìˆ˜ ë‹¨ê³„ ì„ íƒ", [stage['stage'] for stage in json_data['training_stages']])

generate_btn = st.button("âœ¨ ìƒì„±í•˜ê¸°")

# HWP ë° PDF íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
@st.cache_resource(show_spinner="ì—…ë¡œë“œí•œ íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
def process_uploaded_file(file):
    file_content = file.read()
    file_path = f"./.cache/files/{file.name}"
    with open(file_path, "wb") as f:
        f.write(file_content)

    # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ë¡œë” ì„ íƒ
    if file.name.endswith(".hwp") or file.name.endswith(".hwpx"):
        loader = HWPLoader(file_path)
    elif file.name.endswith(".pdf"):
        loader = PDFPlumberLoader(file_path)
    else:
        st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        return None

    # ë¬¸ì„œ ë¡œë“œ
    docs = loader.load()

    # ë¬¸ì„œ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
    split_documents = text_splitter.split_documents(docs)

    # ì„ë² ë”© ìƒì„±
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=openai_api_key)

    # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)

    # ê²€ìƒ‰ê¸° ìƒì„±
    retriever = vectorstore.as_retriever()

    # ë¬¸ì„œ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    document_text = " ".join([doc.page_content for doc in docs])
    
    return retriever, document_text

# ì²´ì¸ ìƒì„± í•¨ìˆ˜
def create_chain(content_option, level_option, uploaded_file_content):
    # JSON ë°ì´í„°ì—ì„œ ì„ íƒëœ ì˜µì…˜ì— í•´ë‹¹í•˜ëŠ” ì„¤ëª…ì„ ì°¾ê¸°
    stage_description = next((stage['description'] for stage in json_data['training_stages'] if stage['stage'] == level_option), "")
    content_items = next((content['items'] for content in json_data['content_standards'] if content['category'] == content_option), [])
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""
    ì—°ìˆ˜ ê³„íšì„œì— ê¸°ì´ˆí•œ ë””ì§€í„¸ ë°°ì§€ ì„¤ëª…ê³¼ ë°œê¸‰ ì¡°ê±´ì„ ì œì‹œí•˜ì„¸ìš”.
    
    ë””ì§€í„¸ ë°°ì§€ ì„¤ëª…: {uploaded_file_content}ì† ë‚´ìš©ì„ ì£¼ì œ: {content_option}, ë‹¨ê³„: {level_option}, ë‹¨ê³„ ì„¤ëª…: {stage_description}, ë‚´ìš© ìš”ì†Œ: {"; ".join(content_items)}ë¡œ í•´ì„í•´ì„œ ë°œê¸‰í•  ë””ì§€í„¸ ë°°ì§€ ì„¤ëª… ë‚´ìš©ì„ 200ìë¡œ ì¶œë ¥
    
    ë°°ì§€ ë°œê¸‰ ì¡°ê±´: ì—°ìˆ˜ê³¼ì •ëª…, ì—°ìˆ˜ê¸°ê°„, ì—°ìˆ˜ì¥ì†Œ, ì—°ìˆ˜ì£¼ê´€ê¸°ê´€, ì´ìˆ˜ ì‹œê°„ ë“± {uploaded_file_content}ì—ì„œ ì¶”ì¶œí•œ ì •ë³´ë¥¼ 200ìë¡œ ì¶œë ¥
    """
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=openai_api_key)

    # ì²´ì¸ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    def run_chain(prompt):
        response = llm(prompt)
        return response.content if hasattr(response, 'content') else str(response)
    
    return run_chain(prompt)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if generate_btn:
    if st.session_state["uploaded_file"] is not None:
        with st.spinner("AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            # ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬
            retriever, uploaded_file_content = process_uploaded_file(st.session_state["uploaded_file"])
            if retriever:
                # ì²´ì¸ í•¨ìˆ˜ ìƒì„± ë° ì‹¤í–‰
                ai_answer = create_chain(content_option, level_option, uploaded_file_content)
                
                # ì‘ë‹µì„ Markdown í˜•ì‹ìœ¼ë¡œ í¬ë§·
                if isinstance(ai_answer, str):
                    markdown_content = ai_answer.replace("\n", "  \n")
                    # ì‘ë‹µì„ Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
                    st.markdown(markdown_content, unsafe_allow_html=True)
                else:
                    st.error("AI ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("ì—°ìˆ˜ê³„íšì„œë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")
